{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12990330,"sourceType":"datasetVersion","datasetId":8222320}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"shymaaelbana/vessel-mamba-mra\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom math import sqrt\nimport numpy as np\nimport tqdm\nfrom collections import OrderedDict\nimport scipy.io\nimport pickle\nimport nibabel as nib\nimport os\nimport getpass\nfrom sklearn.preprocessing import MinMaxScaler\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SCRIPT CONFIGURATION\n# All user-configurable parameters are centralized here.","metadata":{}},{"cell_type":"code","source":"'''\nThose are the arguments that you should focus on \nimage_folder: Contains path for the images \nnum_iters: is for how many epochs you want train the model\nstart_image: The image that you want to start at it\nend_image: The image that you want to end at it\ntrain_batch_size: try to find the best tradeoff between speed in training and psnr\nnum_layers: no.of layers in network \nlayer_size: no.of weights in each layer\n'''\nCONFIG = {\n    # --- I/O Configuration ---\n    \"image_folder\": '/kaggle/input/vessel-mamba-mra/MambaVesselNet_dataset_MRA_multiclass/imagesTr/',\n    \"base_results_dir\": f\"./results_fast_{getpass.getuser()}\",\n    \"reconstruction_dir\": \"./reconstructed_images\",\n\n    # --- File Selection (1-based index) ---\n    \"start_image\": 1, # The image that you want to start at it \n    \"end_image\": 28, # The image that you want to stop at it \n\n    # --- Training Hyperparameters ---\n    \"learning_rate\": 1e-4,\n    \"num_iters\": 5000,\n    # Set to a specific integer (e.g., 131072 * 8 this batch size is good for 2xt4 and most probably you should increase it for a100) or (None for auto-calculation: not recommended at least for t4).\n    \"train_batch_size\": 131072 * 8,\n    \"seed\": 42,\n    \"use_amp\": True,  # Use Automatic Mixed Precision for training\n    \"log_frequency\": 10,  # Log PSNR and loss every N iterations\n\n    # --- Model (SIREN) Architecture ---\n    \"num_layers\": 5,\n    \"layer_size\": 512,  # Hidden dimension size\n    \"w0\": 30.0,         # w0 for subsequent SIREN layers\n    \"w0_initial\": 30.0, # w0 for the first SIREN layer\n\n    # --- Reconstruction Parameters ---\n    # Set to a specific integer or None for auto-calculation.\n    \"inference_batch_size\": None,\n\n    # --- Automatic Batch Size Calculator (Advanced) ---\n    \"mem_usage_factor\": 0.70,        # Use 70% of available VRAM for training batches\n    \"min_calc_batch_size\": 16384,\n    \"max_calc_batch_size\": 4 * 1024 * 1024,\n    \"voxel_divisor\": 4,              # Ensures batch size is at most total_voxels / N\n    \"non_cuda_batch_size\": 65536,    # Fallback batch size for CPU training\n\n    # --- Automatic Inference Batch Size Calculator (Advanced) ---\n    \"inference_mem_factor\": 0.60,    # Use 60% of VRAM for inference batches\n    \"max_inference_batch_size\": 1 * 1024 * 1024,\n    \"non_cuda_inference_batch_size\": 65536, # Fallback for CPU inference\n\n    # --- Filename Configuration ---\n    # These are the BASE filenames. The script will automatically PREPEND the\n    # original image name to them (e.g., 'image_01_best_model.pt').\n    \"model_filename\": 'best_model.pt',\n    \"scaler_filename\": 'scaler.pkl',\n    \"header_filename\": 'nifti_header.pkl',\n    \"metadata_filename\": 'metadata.pkl',\n    \"coords_filename\": 'input_coords.mat',\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UTILITY: FAST BATCH SIZE CALCULATOR\n","metadata":{}},{"cell_type":"code","source":"def calculate_optimal_batch_size(model, device, voxel_count, config):\n    \"\"\"Dynamically calculates an optimal batch size based on available VRAM.\"\"\"\n    if not torch.cuda.is_available():\n        return config['non_cuda_batch_size']\n\n    free_mem, total_mem = torch.cuda.mem_get_info()\n    model_params = sum(p.numel() * p.element_size() for p in model.parameters())\n    hidden_size = model.net[0].linear.out_features\n    num_layers = len(model.net)\n    bytes_per_sample = 4 * hidden_size * (2 * num_layers + 3) # Heuristic\n    available_for_batch = (free_mem - model_params) * config['mem_usage_factor']\n    \n    max_batch = int(available_for_batch / bytes_per_sample)\n    max_batch = min(max_batch, voxel_count // config['voxel_divisor'])\n    max_batch = max(config['min_calc_batch_size'], min(max_batch, config['max_calc_batch_size']))\n    \n    # This now calculates the batch size for just one GPU.\n    batch_size = 2 ** int(np.log2(max_batch))\n\n    print(f\"\\n{'='*70}\\nQUICK BATCH SIZE CALCULATION\\n{'='*70}\")\n    print(f\"Detected 1 GPU.\") # MODIFIED: Hardcoded to 1 GPU for clarity.\n    print(f\"GPU Memory: {free_mem/1e9:.1f} GB free / {total_mem/1e9:.1f} GB total\")\n    print(f\"Calculated optimal batch size: {batch_size:,}\")\n    print(f\"Memory per sample (estimated): {bytes_per_sample:,} bytes\")\n    print(f\"Expected batch memory usage: {batch_size * bytes_per_sample / 1e9:.2f} GB\")\n    print(f\"{'='*70}\\n\")\n    \n    return batch_size","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL: SIREN\n","metadata":{}},{"cell_type":"code","source":"class OptimizedSirenLayer(nn.Module):\n    def __init__(self, dim_in, dim_out, w0=30., c=6., is_first=False, use_bias=True):\n        super().__init__()\n        self.dim_in, self.is_first, self.w0 = dim_in, is_first, w0\n        self.linear = nn.Linear(dim_in, dim_out, bias=use_bias)\n        w_std = (1 / dim_in) if is_first else (sqrt(c / dim_in) / w0)\n        nn.init.uniform_(self.linear.weight, -w_std, w_std)\n        if use_bias:\n            nn.init.uniform_(self.linear.bias, -w_std, w_std)\n    \n    def forward(self, x):\n        return torch.sin(self.w0 * self.linear(x))\n\n\nclass OptimizedSiren(nn.Module):\n    def __init__(self, dim_in, dim_hidden, dim_out, num_layers, w0=30.,\n                 w0_initial=30., use_bias=True):\n        super().__init__()\n        layers = []\n        for i in range(num_layers):\n            is_first = (i == 0)\n            layer_w0 = w0_initial if is_first else w0\n            layer_dim_in = dim_in if is_first else dim_hidden\n            layers.append(OptimizedSirenLayer(\n                dim_in=layer_dim_in, dim_out=dim_hidden, w0=layer_w0,\n                use_bias=use_bias, is_first=is_first\n            ))\n        self.net = nn.Sequential(*layers)\n        self.last_layer = nn.Linear(dim_hidden, dim_out, bias=use_bias)\n        w_std = sqrt(6. / dim_hidden) / w0\n        nn.init.uniform_(self.last_layer.weight, -w_std, w_std)\n        if use_bias:\n            nn.init.uniform_(self.last_layer.bias, -w_std, w_std)\n    \n    def forward(self, x):\n        return self.last_layer(self.net(x))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA UTILITIES\n","metadata":{}},{"cell_type":"code","source":"\ndef to_coordinates_and_features_3D(img_tensor):\n    \"\"\"Converts a 4D image tensor (C, D, H, W) to coordinates and features.\"\"\"\n    C, D, H, W = img_tensor.shape\n    d_coords, h_coords, w_coords = torch.meshgrid(\n        torch.linspace(-1.0, 1.0, D),\n        torch.linspace(-1.0, 1.0, H),\n        torch.linspace(-1.0, 1.0, W),\n        indexing='ij'\n    )\n    coordinates = torch.stack([d_coords, h_coords, w_coords], dim=-1).reshape(-1, 3)\n    features = img_tensor.permute(1, 2, 3, 0).reshape(-1, C)\n    return coordinates, features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CORE: FAST TRAINER\n","metadata":{}},{"cell_type":"code","source":"class FastTrainer:\n    def __init__(self, model, lr):\n        use_fused = 'fused' in torch.optim.AdamW.__init__.__kwdefaults__\n      \n        params = model.parameters()\n        self.optimizer = torch.optim.AdamW(params, lr=lr, fused=use_fused)\n        \n        self.model = model\n        self.loss_func = nn.MSELoss()\n        self.best_vals = {'psnr': 0.0, 'loss': float('inf')}\n        self.logs = {'psnr': [], 'loss': []}\n        self.best_model = OrderedDict()\n        \n        self.last_psnr = 0.0\n        \n        self.scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None\n\n    def train(self, coordinates, features, num_iters, batch_size, log_frequency, use_amp):\n        N = coordinates.shape[0]\n        device = coordinates.device\n\n        print(f\"\\n{'='*70}\\nTRAINING START\\n{'='*70}\")\n        print(f\"Batch size: {batch_size:,} ({batch_size/N*100:.2f}% of {N:,} total voxels)\")\n        print(f\"Iterations: {num_iters:,}\")\n        print(f\"Mixed precision (AMP): {use_amp and self.scaler is not None}\")\n        print(f\"{'='*70}\\n\")\n        \n        idx_buffer = torch.empty(batch_size, dtype=torch.long, device=device)\n        \n        self.model.train()\n        with tqdm.trange(num_iters, ncols=120, postfix={'loss': 'N/A', 'psnr': 'N/A', 'best': 'N/A'}) as pbar:\n            for i in pbar:\n                idx_buffer.random_(0, N)\n                batch_coords = coordinates[idx_buffer]\n                batch_feats = features[idx_buffer]\n                \n                self.optimizer.zero_grad(set_to_none=True)\n                \n                if use_amp and self.scaler is not None:\n                    with torch.amp.autocast('cuda'):\n                        pred = self.model(batch_coords)\n                        loss = self.loss_func(pred, batch_feats)\n                    self.scaler.scale(loss).backward()\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                else:\n                    pred = self.model(batch_coords)\n                    loss = self.loss_func(pred, batch_feats)\n                    loss.backward()\n                    self.optimizer.step()\n                \n                if i % log_frequency == 0:\n                    with torch.no_grad():\n                        mse = (pred.detach() - batch_feats).pow(2).mean()\n                        psnr_val = 20 * torch.log10(torch.tensor(1.0)) - 10 * torch.log10(mse)\n                    \n                    self.last_psnr = psnr_val.item()\n                    self.logs['psnr'].append(self.last_psnr)\n                    self.logs['loss'].append(loss.item())\n                    \n                    if self.last_psnr > self.best_vals['psnr']:\n                        self.best_vals['psnr'] = self.last_psnr\n                        self.best_vals['loss'] = loss.item()\n                        \n                   \n                        state_to_save = self.model.state_dict()\n                        for k, v in state_to_save.items():\n                            self.best_model[k] = v.detach().clone().cpu()\n                \n                pbar.set_postfix(\n                    loss=f\"{loss.item():.6f}\", \n                    psnr=f\"{self.last_psnr:.2f}\", \n                    best=f\"{self.best_vals['psnr']:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MAIN WORKFLOW: TRAINING\n","metadata":{}},{"cell_type":"code","source":"def train_siren_optimized(config):\n    \"\"\"Main function to orchestrate the training of a SIREN model.\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    torch.manual_seed(config['seed'])\n    \n    logdir = config['logdir']\n    if not os.path.exists(logdir):\n        os.makedirs(logdir)\n    \n    print(\"\\n\" + \"=\"*70 + f\"\\nFAST SIREN TRAINING: {os.path.basename(config['image'])}\\n\" + \"=\"*70)\n    print(f\"Device: {device}\")\n    if torch.cuda.is_available(): print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    \n    img_nii = nib.load(config['image'])\n    img_data = img_nii.get_fdata().astype(np.float32)\n    img_data = img_data[np.newaxis, ...] if img_data.ndim == 3 else np.transpose(img_data, (3, 0, 1, 2))\n    img_tensor = torch.from_numpy(img_data)\n    C, D, H, W = img_tensor.shape\n    coordinates, features = to_coordinates_and_features_3D(img_tensor)\n    \n    scaler = MinMaxScaler(feature_range=(0, 1))\n    features = torch.from_numpy(scaler.fit_transform(features.numpy()).astype(np.float32))\n    coordinates, features = coordinates.to(device), features.to(device)\n    \n    model = OptimizedSiren(\n        dim_in=3, dim_hidden=config['layer_size'], dim_out=C,\n        num_layers=config['num_layers'], w0_initial=config['w0_initial'], w0=config['w0']\n    )\n    \n    # The original code would wrap the model here for multi-GPU training.\n    model.to(device)\n    \n    batch_size = config['train_batch_size']\n    if batch_size is None:\n        batch_size = calculate_optimal_batch_size(model, device, coordinates.shape[0], config)\n    \n    trainer = FastTrainer(model, lr=config['learning_rate'])\n    trainer.train(coordinates, features, config['num_iters'], batch_size, config['log_frequency'], config['use_amp'])\n    \n    print(f\"\\n{'='*70}\\nâœ… TRAINING COMPLETE! Best PSNR: {trainer.best_vals['psnr']:.2f} dB\\n{'='*70}\\n\")\n    \n    print(\"ðŸ’¾ Saving model and metadata...\")\n    torch.save(trainer.best_model, os.path.join(logdir, config['model_filename']))\n    with open(os.path.join(logdir, config['scaler_filename']), 'wb') as f: pickle.dump(scaler, f)\n    with open(os.path.join(logdir, config['header_filename']), 'wb') as f: pickle.dump(img_nii.header.copy(), f)\n    \n    metadata = {\n        'img_shape': (C, D, H, W),\n        'model_config': {'dim_in': 3, 'dim_hidden': config['layer_size'], 'dim_out': C, 'num_layers': config['num_layers'], 'w0': config['w0'], 'w0_initial': config['w0_initial']},\n        'best_psnr': trainer.best_vals['psnr'], 'best_loss': trainer.best_vals['loss']\n    }\n    with open(os.path.join(logdir, config['metadata_filename']), 'wb') as f: pickle.dump(metadata, f)\n    scipy.io.savemat(os.path.join(logdir, config['coords_filename']), {'input_coordinates': coordinates.cpu().numpy()})\n    \n    print(f\"âœ“ All files saved to: {logdir}\\n\")\n    return trainer.best_model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MAIN WORKFLOW: RECONSTRUCTION\n","metadata":{}},{"cell_type":"code","source":"\ndef reconstruct_from_siren(model_dir, output_path, config):\n    \"\"\"Reconstructs an image from a trained SIREN model directory.\"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"\\n\" + \"=\"*70 + \"\\nFAST RECONSTRUCTION\\n\" + \"=\"*70)\n    \n    with open(os.path.join(model_dir, config['metadata_filename']), 'rb') as f: metadata = pickle.load(f)\n    C, D, H, W = metadata['img_shape']\n    with open(os.path.join(model_dir, config['scaler_filename']), 'rb') as f: scaler = pickle.load(f)\n    with open(os.path.join(model_dir, config['header_filename']), 'rb') as f: header = pickle.load(f)\n    coords_data = scipy.io.loadmat(os.path.join(model_dir, config['coords_filename']))\n    coordinates = torch.from_numpy(coords_data['input_coordinates']).to(device)\n    \n    model = OptimizedSiren(**metadata['model_config'])\n    model.load_state_dict(torch.load(os.path.join(model_dir, config['model_filename']), map_location=device))\n    \n    model.to(device).eval()\n    print(f\"âœ“ Model loaded from: {model_dir}\")\n    \n    batch_size = config['inference_batch_size']\n    if batch_size is None:\n        if torch.cuda.is_available():\n            free_mem = torch.cuda.mem_get_info()[0]\n            est_mem_per_item = 4 * metadata['model_config']['dim_hidden']\n            batch_size = min(config['max_inference_batch_size'], int(free_mem * config['inference_mem_factor'] / est_mem_per_item))\n            batch_size = 2 ** int(np.log2(batch_size))\n        else:\n            batch_size = config['non_cuda_inference_batch_size']\n\n    N = coordinates.shape[0]\n    num_batches = (N + batch_size - 1) // batch_size\n    print(f\"\\nInference batch size: {batch_size:,}\\nTotal batches: {num_batches:,}\\n\")\n    \n    predictions = []\n    with torch.no_grad():\n        for i in tqdm.trange(num_batches, desc=\"Reconstructing\", ncols=100):\n            coord_batch = coordinates[i * batch_size: (i + 1) * batch_size]\n            with torch.amp.autocast('cuda',enabled=config['use_amp']):\n                pred_batch = model(coord_batch)\n            predictions.append(pred_batch.cpu())\n    \n    predicted_features = scaler.inverse_transform(torch.cat(predictions, dim=0).numpy())\n    img_decompressed = predicted_features.T.reshape(C, D, H, W)\n    img_decompressed = np.transpose(img_decompressed, (1, 2, 3, 0))\n    if C == 1: img_decompressed = np.squeeze(img_decompressed, axis=-1)\n    \n    nib.save(nib.nifti1.Nifti1Image(img_decompressed, None, header=header), output_path)\n    print(f\"\\nâœ“ Saved reconstruction to: {output_path}\\n\")\n    return img_decompressed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SCRIPT EXECUTION\n","metadata":{}},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    os.makedirs(CONFIG['base_results_dir'], exist_ok=True)\n    os.makedirs(CONFIG['reconstruction_dir'], exist_ok=True)\n    \n    try:\n        all_files = sorted([f for f in os.listdir(CONFIG['image_folder']) if f.endswith(('.nii', '.nii.gz'))])\n        if not all_files: raise FileNotFoundError\n    except FileNotFoundError:\n        print(f\"Error: No '.nii' or '.nii.gz' files found in '{CONFIG['image_folder']}'. Please check the path.\")\n        exit()\n\n    start_idx = CONFIG['start_image'] - 1\n    end_idx = CONFIG['end_image']\n    files_to_process = all_files[start_idx:end_idx]\n\n    print(f\"Found {len(all_files)} total images. Processing {len(files_to_process)} images from index {CONFIG['start_image']} to {CONFIG['end_image']}.\")\n    print(\"-\" * 50)\n\n    for i, filename in enumerate(files_to_process):\n        print(f\"\\n\\n{'='*80}\")\n        print(f\"PROCESSING IMAGE {i+1}/{len(files_to_process)} (Overall index: {start_idx + i + 1}): {filename}\")\n        print(f\"{'='*80}\\n\")\n        \n        current_config = CONFIG.copy()\n        \n        image_name_no_ext = os.path.splitext(os.path.splitext(filename)[0])[0]\n\n        filename_keys_to_prefix = [\n            \"model_filename\", \"scaler_filename\", \"header_filename\",\n            \"metadata_filename\", \"coords_filename\"\n        ]\n        for key in filename_keys_to_prefix:\n            original_value = current_config[key]\n            current_config[key] = f\"{image_name_no_ext}_{original_value}\"\n            \n        current_config['image'] = os.path.join(CONFIG['image_folder'], filename)\n        current_config['logdir'] = os.path.join(CONFIG['base_results_dir'], image_name_no_ext)\n        output_path = os.path.join(CONFIG['reconstruction_dir'], filename)\n        \n        print(f\"--- Step 1: Training on {filename} ---\")\n        train_siren_optimized(current_config)\n        \n        print(f\"--- Step 2: Reconstructing {filename} ---\")\n        reconstruct_from_siren(\n            model_dir=current_config['logdir'],\n            output_path=output_path,\n            config=current_config\n        )\n\n    print(\"\\nâœ… ALL SELECTED IMAGES PROCESSED SUCCESSFULLY!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}